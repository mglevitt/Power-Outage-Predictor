{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Outages\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the severity (number of customers, duration, or demand loss) of a major power outage.\n",
    "    * Predict the cause of a major power outage.\n",
    "    * Predict the number and/or severity of major power outages in the year 2020.\n",
    "    * Predict the electricity consumption of an area.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "In this project, we will be using a classification prediction model to predict, based on given data, if an outage will or will not be severe. For the purposes of this project, we define severity in terms of outage duration, and use a Decision Tree Classifer as the model. This means a longer outage duration will indicate a more severe outage. Of course, we could have defined severity by the number of people affected, or another combination of our given data, but for this purpose we are sticking with outage duration. In order to define an outcome, we set 1 equal to a severe outage and 0 equal to a non severe outage using a Binarizer with a threshhold at the mean outage duration. This, of course, is our target variable. We run a basic baseline model only one-hot-encoding features that need to be, and remove columns that have no affect on the outcome of the data (such as POSTAL.CODE, which is a repeat of STATE). This baseline model has an accuracy of roughly 77%. Then, we build our final model by adding features not present in the dataset, such as the season of the outage. We go more into detail in the \"Final Model\" section. Additionally, we edit our Decision Tree Classifier parameters to get the best outcome that we can. Lastly, we run a fairness evaluation on our model to assess how fair the model accuracy is. Our objective is to increase our accuracy as much as possible. \n",
    "\n",
    "It is important to note that we only have 1540 rows of data over years 2000 to 2016, meaning that it is not valid to say that this data would accurately predict data, for lets say, 2020. This model could be improved with access to more data. \n",
    "### Baseline Model\n",
    "In our baseline model, we use 23 features to predict if the outage is severe (1) or not (0). We use a Binarizer to create an \"Outcome\" column for our classifier model, as stated above. We fill null values in the Outage Duration column with 0, due to results from Project03 that showed null values in duration were often due to intentional attacks and the outage was not long. All other columns were removed due to not having any affect on the model. Below are the labels for each column and if it is nominal, ordinal, or quantitative: \n",
    "'MONTH': N \n",
    "'U.S._STATE': N\n",
    "'NERC.REGION': N\n",
    "'CLIMATE.REGION': N\n",
    "'CAUSE.CATEGORY.DETAIL': N\n",
    "'DEMAND.LOSS.MW': Q\n",
    "'CUSTOMERS.AFFECTED': Q\n",
    "'TOTAL.PRICE': Q\n",
    "'RES.SALES': Q\n",
    "'COM.SALES': Q\n",
    "'IND.SALES': Q\n",
    "'TOTAL.SALES': Q\n",
    "'IND.PERCEN': Q\n",
    "'RES.CUSTOMERS': Q\n",
    "'IND.CUSTOMERS': Q\n",
    "'TOTAL.CUSTOMERS': Q\n",
    "'RES.CUST.PCT': Q\n",
    "'IND.CUST.PCT': Q\n",
    "'PC.REALGSP.REL':Q\n",
    "'PC.REALGSP.CHANGE': Q\n",
    "'TOTAL.REALGSP': Q\n",
    "'POPULATION': Q\n",
    "'Outcome': Ordinal or Nominal?  \n",
    "Our baseline model first does some data cleaning to convert columns that are currently objects into floats. Then, we filter through the columns and add a step to the pipeline to one hot encode any categorical column. We create a column transformer and feed our column transformer into a Pipeline with a Decision Tree Classifier. With X as our predictor variabled and y as our target, we fit and calculate the score which gives the accuracy percent of the model. Baseline, we get 77% accuracy. Overall, this is not a great predictor and can definitely be improved by adding features. \n",
    "\n",
    "### Final Model\n",
    "In our final model, we begin by showing, by example, how generalizing a feature can lead to a better predictor. In this data, there are two columns detailing the category of the outage. One contains more detailed descriptions. In our baseline, we use the detailed descriptions to show how getting too specific can lead to overfitting data and not having a generalized enough model. As a solution, we can categorize similar category details into one category. This is already done in our dataset and is named category, so we drop the details and add in the generalized category. When we re-run our model, we get a 82% accuracy. This increased! Next, we know that seasons are associated with storms that are more likely to set off a severe outage. Thus, we group 'MONTH' into four seasons: winter, spring, summer, and autumn. This means we are generalizing our model to make better predicitions based off the season an outage occured in. We use this column in addition to the orginial ones from the baseline model and increase our accuracy to 86.5%! Lastly, we noticed a quantiative column that had very large values and were a little hard to compare, leading us to believe a log-scale would make comparisons easier, and lead to an overall better model. For the last step, we log-scale the TOTAL.REALGSP column and run the Decision Tree Classifier model again, with a max_depth set to 25 for best parameter, found from grid search. This gives us a 93.6% accuracy overall!\n",
    "\n",
    "### Fairness Evaluation\n",
    "To evaluate the fairness of the final data model we decided to do a permutation test to find accuracy parity utilizing the difference in score between two randomly selected subsets of the data as our test statistic. Our null hypothesis was that the model was not biased in terms of predicting outage severity. Our alternative hypothesis was that the model was not fair. We decided to shuffle the population column and split up our data based on values above and below the median. We chose to utilize the population column to split up our data because it had no null values. Once we got the subsets of the data we ran our final model on each subset of the data and found the score of the model. Then we returned this absolute difference of score as the test statistic. We ran this proccess of getting the test statistic 1000 times to get a distribution of test statistics. We found our p-value based on the proportion of test statistics above a pre-determined threshold. We chose our threshold to be .02 so their was some room for error on the score since our final model was not perfect with a score of around .94. In the end we got a p-value of .02 so we were able to determine that our model was fair at signifigance level of .05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning/Prep\n",
    "This section is the exact same as project03, where we clean the dataset with the appropriate measures needed to create models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data frame\n",
    "df = pd.read_csv('outage.csv')\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANS THE DF INTO A USEABLE FORMAT\n",
    "#grab the columns from the messy dataframe\n",
    "df.columns = df.loc[4]\n",
    "#grab the units\n",
    "units = df.loc[5][1:]\n",
    "#drop unnessessary columns and reset the index\n",
    "df = df.drop([0,1,2,3,4,5]).drop(columns = ['variables']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXING COLUMNS\n",
    "#combine the start and restoration date and times \n",
    "df['OUTAGE.START'] = df['OUTAGE.START.DATE']+\" \"+df['OUTAGE.START.TIME']\n",
    "df['OUTAGE.RESTORATION'] = df['OUTAGE.RESTORATION.DATE']+\" \"+df['OUTAGE.RESTORATION.TIME']\n",
    "\n",
    "#Converting to datetime object\n",
    "df['OUTAGE.START'] = pd.to_datetime(df['OUTAGE.START'])\n",
    "df['OUTAGE.RESTORATION'] = pd.to_datetime(df['OUTAGE.RESTORATION'])\n",
    "df['OUTAGE.START.DATE'] = pd.to_datetime(df['OUTAGE.START.DATE'])\n",
    "df['OUTAGE.RESTORATION.DATE'] = pd.to_datetime(df['OUTAGE.RESTORATION.DATE'])\n",
    "df['OUTAGE.START.TIME'] = pd.to_datetime(df['OUTAGE.START.TIME'])\n",
    "df['OUTAGE.RESTORATION.TIME'] = pd.to_datetime(df['OUTAGE.RESTORATION.TIME'])\n",
    "#We can now drop the orginial columns \n",
    "#sets the index as observatins column\n",
    "df = df.set_index('OBS')\n",
    "#convert datapoints to a float\n",
    "def convert(x):\n",
    "    if x != x:\n",
    "        return x\n",
    "    try:\n",
    "        out = float(x)\n",
    "    except:\n",
    "        out = x\n",
    "    return out\n",
    "#df = df.applymap(convert)\n",
    "df = df[df['OUTAGE.START'].isnull() == False]\n",
    "df = df[df['CLIMATE.REGION'].isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will start to build a model to predict if an outage will be severe. For the purposes of this project, we define severe based off the duration of the outage. If the duration is above the mean outage duration, it will be assigned 1 for severse, else it will be assigned 0 for not severe. We do this using the Binarizer with a threshold set to the mean outage duration in this dataset. We use a fillna value of zero because in our last project, we found NaN values typically meant that the outage was short and unreported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>4</th>\n",
       "      <th>OUTAGE.DURATION</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1740</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "4   OUTAGE.DURATION  Outcome\n",
       "OBS                         \n",
       "1              3060      1.0\n",
       "2                 1      0.0\n",
       "3              3000      1.0\n",
       "4              2550      0.0\n",
       "5              1740      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer \n",
    "#we fill with 0 because these are usually intentional attacks\n",
    "df[['OUTAGE.DURATION']] = df[['OUTAGE.DURATION']].fillna(value = 0)\n",
    "\n",
    "#create a binarizer\n",
    "transformer = Binarizer(threshold = 2550).fit(df[['OUTAGE.DURATION']])\n",
    "#create outcomes based on data\n",
    "outcomes = transformer.transform(df[['OUTAGE.DURATION']])\n",
    "#define the outcomes\n",
    "df['Outcome'] = outcomes\n",
    "display(df[['OUTAGE.DURATION','Outcome']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create our baseline model. This model is pretty basic, only one hot encoding state. We first drop columns with no relationship to the severity prediction. This was done by analyzing relationships between the accuracy with and without the column. Then, we do a little data cleaning with a convert function to turn our data into numerical data. We then grab our X and y variables and check which columns need to be one hot encoded (such as state). After all of this, we stick it in a Column Transformer and Pipeline using a Decision Tree Classifier. This gives us an accuracy of around 77%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data):\n",
    "    #convert items to float\n",
    "    d = data.copy()\n",
    "    def convert(x):\n",
    "        if x != x:\n",
    "            return x\n",
    "        try:\n",
    "            out = float(x)\n",
    "        except:\n",
    "            out = x\n",
    "        return out\n",
    "    d = d.applymap(convert)\n",
    "    steps = []\n",
    "    X = d.drop('Outcome', axis=1)\n",
    "    y = d['Outcome']\n",
    "    #the code below one hot encodes any string column\n",
    "    for col in d.columns:\n",
    "        typ = type(d[col][0])\n",
    "        if typ == str:\n",
    "            steps.append((col,OneHotEncoder(handle_unknown='ignore'),[col]))\n",
    "\n",
    "    col_t = ('col_trans',ColumnTransformer(steps))\n",
    "    pl = Pipeline([col_t,('tree', DecisionTreeClassifier())])\n",
    "\n",
    "    fitted = pl.fit(X, y)\n",
    "    accuracy = pl.score(X, y)\n",
    "    return pl, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7743421052631579"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop cols with no relationship\n",
    "data = df.drop(columns = ['YEAR','POSTAL.CODE','OUTAGE.START.DATE','OUTAGE.START.TIME','OUTAGE.RESTORATION.TIME',\n",
    "                  'OUTAGE.RESTORATION.DATE','CAUSE.CATEGORY','HURRICANE.NAMES','POPPCT_URBAN',\n",
    "       'POPPCT_UC', 'POPDEN_URBAN', 'POPDEN_UC', 'POPDEN_RURAL','OUTAGE.START','OUTAGE.RESTORATION', 'ANOMALY.LEVEL',\n",
    "                         'RES.PRICE','COM.CUSTOMERS','COM.CUST.PCT','PC.REALGSP.USA',\n",
    "                         'UTIL.REALGSP','AREAPCT_UC','IND.PRICE','PCT_WATER_TOT','CLIMATE.CATEGORY',\n",
    "                         'PC.REALGSP.STATE','AREAPCT_URBAN','COM.PRICE','PI.UTIL.OFUSA',\n",
    "                          'PCT_LAND','PCT_WATER_INLAND','RES.PERCEN','COM.PERCEN','UTIL.CONTRI', 'OUTAGE.DURATION'])\n",
    "pl, acc = run_model(data)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the below function to see which features are most important to our dataset. Customers affected, for example, has a large affect on the outcome, as well as the NERC region of the outage, population, and total real GSP contributed by all industries. We can use this information to extract new features that may help our accuracy in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MONTH': 0.0001506536519306383,\n",
       " 'U.S._STATE': 0.00018379674057494776,\n",
       " 'NERC.REGION': 0.009824450414607656,\n",
       " 'CLIMATE.REGION': 1.9761886119325722e-05,\n",
       " 'CAUSE.CATEGORY': 0.0,\n",
       " 'OUTAGE.DURATION': 0.005503415887121589,\n",
       " 'DEMAND.LOSS.MW': 0.028287781270694267,\n",
       " 'CUSTOMERS.AFFECTED': 0.00017582212434864955,\n",
       " 'TOTAL.PRICE': 0.0005781809330629655,\n",
       " 'RES.SALES': 0.0015168466536754615,\n",
       " 'COM.SALES': 0.002625401259704883,\n",
       " 'IND.SALES': 9.761385602670174e-05,\n",
       " 'TOTAL.SALES': 0.008679519136865356,\n",
       " 'IND.PERCEN': 0.006117031174440262,\n",
       " 'RES.CUSTOMERS': 0.004434647756593718,\n",
       " 'IND.CUSTOMERS': 0.006798286501802084,\n",
       " 'TOTAL.CUSTOMERS': 0.004924339407073903,\n",
       " 'RES.CUST.PCT': 1.1691002465366075e-05,\n",
       " 'IND.CUST.PCT': 0.0,\n",
       " 'PC.REALGSP.REL': 0.0,\n",
       " 'PC.REALGSP.CHANGE': 0.31588040855315874,\n",
       " 'TOTAL.REALGSP': 0.014462762871960608,\n",
       " 'POPULATION': 0.0,\n",
       " 'SEASON': 0.009906151042612723}"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree = pl['tree']\n",
    "#We can use the dictionary to see what cols are necessary! \n",
    "dict(zip(X.columns, dec_tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this baseline model, we have a max tree depth of 31 and 139 number of nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tree depth: \n",
      "31\n",
      "Number of nodes: \n",
      "139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Max tree depth: \"),print(dec_tree.tree_.max_depth)\n",
    "print(\"Number of nodes: \"),print(dec_tree.tree_.node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first steps we can take is to generalize our data better. For example, we can change CAUSE.CATEGORY.DETAIL into just CAUSE.CATEGORY, grouping similar outage types together. Luckily, this is already done for us in the dataset. After adding this change, accuracy goes from 77% to 82%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data1 = df.drop(columns = ['YEAR','POSTAL.CODE','OUTAGE.START.DATE','OUTAGE.START.TIME','OUTAGE.RESTORATION.TIME',\n",
    "                  'OUTAGE.RESTORATION.DATE','CAUSE.CATEGORY.DETAIL','HURRICANE.NAMES','POPPCT_URBAN',\n",
    "       'POPPCT_UC', 'POPDEN_URBAN', 'POPDEN_UC', 'POPDEN_RURAL','OUTAGE.START','OUTAGE.RESTORATION', 'ANOMALY.LEVEL',\n",
    "                         'RES.PRICE','COM.CUSTOMERS','COM.CUST.PCT','PC.REALGSP.USA',\n",
    "                         'UTIL.REALGSP','AREAPCT_UC','IND.PRICE','PCT_WATER_TOT','CLIMATE.CATEGORY',\n",
    "                         'PC.REALGSP.STATE','AREAPCT_URBAN','COM.PRICE','PI.UTIL.OFUSA',\n",
    "                          'PCT_LAND','PCT_WATER_INLAND','RES.PERCEN','COM.PERCEN','UTIL.CONTRI'])\n",
    "\n",
    "\n",
    "pl, acc = run_model(final_data1)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add more features to our dataset to get a better model. When it comes to power outages,\n",
    "seasons may categorize the chance of a severe outage better. For example, winter ice storms and summer thunderstorms may have a higher impact than the occasional spring shower. With this assumption, we can categorize our MONTH column into four seasons: Spring, Summer, Autumn, and Winter. Then, we can one hot encode the Seasons column and run the model again. After completing this step, our accuracy jumps 4% to 86.5%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644736842105263"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The seasons are defined as:\n",
    "#spring (March, April, May), \n",
    "#summer (June, July, August), \n",
    "#autumn (September, October, November) and \n",
    "#winter (December, January, February).\n",
    "\n",
    "#Create a replacement dictionary \n",
    "season_dict = {1:'Winter', 2:'Winter',3:'Spring',4:'Spring',5:'Spring',\n",
    "              6:'Summer',7:'Summer',8:'Summer',9:'Autumn',10:'Autumn',\n",
    "              11:'Autumn',12:'Winter'}\n",
    "\n",
    "#drop irrelevant columns \n",
    "final_data2 = df.drop(columns = ['YEAR','POSTAL.CODE','OUTAGE.START.DATE','OUTAGE.START.TIME','OUTAGE.RESTORATION.TIME',\n",
    "                  'OUTAGE.RESTORATION.DATE','CAUSE.CATEGORY.DETAIL','HURRICANE.NAMES','POPPCT_URBAN',\n",
    "       'POPPCT_UC', 'POPDEN_URBAN', 'POPDEN_UC', 'POPDEN_RURAL','OUTAGE.START','OUTAGE.RESTORATION', 'ANOMALY.LEVEL',\n",
    "                         'RES.PRICE','COM.CUSTOMERS','COM.CUST.PCT','PC.REALGSP.USA',\n",
    "                         'UTIL.REALGSP','AREAPCT_UC','IND.PRICE','PCT_WATER_TOT','CLIMATE.CATEGORY',\n",
    "                         'PC.REALGSP.STATE','AREAPCT_URBAN','COM.PRICE','PI.UTIL.OFUSA',\n",
    "                          'PCT_LAND','PCT_WATER_INLAND','RES.PERCEN','COM.PERCEN','UTIL.CONTRI'])\n",
    "# convert items to float (we do this outside because month needs to be a float)\n",
    "def convert(x):\n",
    "    if x != x:\n",
    "        return x\n",
    "    try:\n",
    "        out = float(x)\n",
    "    except:\n",
    "        out = x\n",
    "    return out\n",
    "final_data2 = final_data2.applymap(convert)\n",
    "\n",
    "# replace the months with season and add a column to the dataset\n",
    "final_data2['SEASON'] = final_data2['MONTH'].replace(season_dict)\n",
    "# run the model \n",
    "pl, acc = run_model(final_data2)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an 86% accuracy, we can create another feature to increase our accuracy again. To do this, we reference our dictionary of important features from the baseline model section. There, we see that 'TOTAL.REALGSP' is considered one of the most important features in this model. Below, we check out some basic stats on this specific column. Since it seems there is a skewness in the data with large values, and a decently large standard deviation, we can log-scale this column to have our values more equally spaced. This, in return, should help in comparisons when creating our model and lead to a higher accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>4</th>\n",
       "      <th>TOTAL.REALGSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.520000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.721794e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.290742e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.681100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.497585e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.074030e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.071033e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.317466e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "4      TOTAL.REALGSP\n",
       "count   1.520000e+03\n",
       "mean    6.721794e+05\n",
       "std     6.290742e+05\n",
       "min     2.681100e+04\n",
       "25%     2.497585e+05\n",
       "50%     4.074030e+05\n",
       "75%     1.071033e+06\n",
       "max     2.317466e+06"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data2[['TOTAL.REALGSP']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, our final model gets a 93.6% accuracy as we expected! Now, the last step is to mess with the parameters of our Decision Tree Classifier. When we run a quick grid search, we find that having a max_depth of 25 helps our model the most, and keeping a default on other parameters is best. This means we have gone from a 77% baseline model to a 93.6% final model!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368421052631579"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_final_model(data):\n",
    "    #convert items to float\n",
    "    d = data.copy()\n",
    "    def convert(x):\n",
    "        if x != x:\n",
    "            return x\n",
    "        try:\n",
    "            out = float(x)\n",
    "        except:\n",
    "            out = x\n",
    "        return out\n",
    "    d = d.applymap(convert)\n",
    "    steps = [('log-scale',FunctionTransformer(np.log),['TOTAL.REALGSP'])]\n",
    "    X = d.drop('Outcome', axis=1)\n",
    "    y = d['Outcome']\n",
    "    #the code below one hot encodes any string column\n",
    "    for col in d.columns:\n",
    "        typ = type(d[col][0])\n",
    "        if typ == str:\n",
    "            steps.append((col,OneHotEncoder(handle_unknown='ignore'),[col]))\n",
    "\n",
    "    col_t = ('col_trans',ColumnTransformer(steps))\n",
    "    pl = Pipeline([col_t,('tree', DecisionTreeClassifier(max_depth = 25))])\n",
    "\n",
    "    fitted = pl.fit(X, y)\n",
    "    accuracy = pl.score(X, y)\n",
    "    return pl, accuracy\n",
    "final_pl, final_acc = run_final_model(final_data2)\n",
    "final_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025657894736842105"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_t_stat(data):\n",
    "    '''Function to get a t_stat for difference of scores between 2 random subsets of the data'''\n",
    "    #Create copy of the data so original df is not manipulated\n",
    "    df = data.copy()\n",
    "    #Shuffles the column 'POPULATION'\n",
    "    df['POPULATION'] = np.random.permutation(df['POPULATION'].values)\n",
    "    #Split into 2 subsets of the data to do permutation test based on whether or not the values of 'POPULATION'\n",
    "    #based on whether they are above or below median.\n",
    "    temp = data.copy()\n",
    "    median = temp['POPULATION'].sort_values()[df.shape[0] // 2]\n",
    "    df1 = df[df['POPULATION'] >= median]\n",
    "    df2 = df[df['POPULATION'] < median]\n",
    "    #compare the absolute difference of score for each subset as my t_stat\n",
    "    pl1, score1 = run_final_model(df1)\n",
    "    pl2, score2 = run_final_model(df2)\n",
    "    t_stat = abs(score1 - score2)\n",
    "    return t_stat\n",
    "t_stats = []\n",
    "#Create a distribution of N t_stats\n",
    "N = 1000\n",
    "for i in range(N):\n",
    "    t_stats.append(get_t_stat(final_data2))\n",
    "#Get p_value based on amount of t_stats over a predetermined threshold\n",
    "threshold = .02\n",
    "p_value = np.count_nonzero(np.array(t_stats) > threshold) / final_data2.shape[0]\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
